{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>There are 2 datasets:</strong><br/>\n",
    "<ol>\n",
    "<li>Training data set,</li>\n",
    "<li>Test data set.</li>\n",
    "</ol>\n",
    "Each of these data sets are .csv files. <br/>\n",
    "Each dataset has 785 columns with a variable number of rows.\n",
    "We shall use the pandas package to read these files. The results are numpy arrays.\n",
    "The training data set has 60,000 test cases and the test data set has 10,000 cases.\n",
    "\n",
    "We shall use the pandas package to read these files. The results are numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"C:\\\\Apps\\\\Projects\\\\ml\\\\data\\\\mnist\\\\\"\n",
    "training_filename = root_dir + \"mnist_train.csv\"\n",
    "# Use pandas to read csv file\n",
    "tmp=pd.read_csv(training_filename, sep=',', header=None)\n",
    "# Use df.loc to access a group of rows and columns\n",
    "# Use .values to return the numpy representation.\n",
    "\n",
    "# Read the training data set\n",
    "x_train, y_train=tmp.loc[:,1:tmp.shape[1]].values, tmp.loc[:,0].values\n",
    "\n",
    "# Read the test data set\n",
    "test_filename = root_dir + \"mnist_test.csv\"\n",
    "tmp=pd.read_csv(test_filename, sep=',', header=None)\n",
    "x_test, y_test=tmp.loc[:,1:tmp.shape[1]].values, tmp.loc[:,0].values\n",
    "tmp=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# Just checking the array dimensions\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[5 0 4 1 9]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0:5,:])\n",
    "print(y_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The digit for index 17 is 8\n"
     ]
    }
   ],
   "source": [
    "index=17\n",
    "curr_image=np.resize(x_train[index, :], (28, 28))\n",
    "plt.imshow(curr_image, cmap='Greys_r')\n",
    "plt.show()\n",
    "print(\"The digit for index {0} is {1}\".format(index, y_train[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_path = 'logging/' # logging path\n",
    "batch_size = 100 # batch size while performing training \n",
    "learning_rate = 0.003 # Learning rate \n",
    "training_epochs = 20 # training epoch\n",
    "display_epoch = 1\n",
    "N1 = 300\n",
    "N2 = 300\n",
    "N3 = 100\n",
    "N4 = 60\n",
    "N5 = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = tf.placeholder(dtype=tf.int32, shape=[], name=\"foo1\")       shape takes a single scalar value directly.\n",
    "# y = tf.placeholder(dtype=tf.int32, shape=[None], name=\"foo2\")   shape takes a 1-dim array\n",
    "# z = tf.placeholder(dtype=tf.int32, shape=None, name=\"foo3\")     shape can take in any value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, 784), name='X_Vector')\n",
    "XX = tf.reshape(X, [-1, 784])\n",
    "Y_  = tf.placeholder(tf.float32, shape=(None, 10), name='Y_Vector')\n",
    "lr = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 784)\n",
      "(?, 10)\n"
     ]
    }
   ],
   "source": [
    "print(XX.shape)\n",
    "print(Y_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A variable maintains state in the graph across calls to run()\n",
    "# Create a variable.\n",
    "# w = tf.Variable(<initial-value>, name=<optional-name>, shape=<optional-shape>)\n",
    "\n",
    "# Truncated normal Outputs random values from a truncated normal distribution.\n",
    "#\n",
    "# tf.random.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.dtypes.float32, seed=None, name=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the weights vector\n",
    "W1 = tf.Variable(tf.truncated_normal([784, N1], stddev=0.1))\n",
    "# Create the bias term\n",
    "B1 = tf.Variable(tf.zeros([N1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = tf.nn.sigmoid(tf.matmul(XX, W1) + B1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = tf.Variable(tf.truncated_normal([N1, N2], stddev=0.1)) \n",
    "B2 = tf.Variable(tf.ones([N2])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y2 = tf.nn.sigmoid(tf.matmul(Y1, W2) + B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "W3 = tf.Variable(tf.truncated_normal([N2, N3], stddev=0.1))\n",
    "B3 = tf.Variable(tf.ones([N3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y3 = tf.nn.sigmoid(tf.matmul(Y2, W3) + B3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "W4 = tf.Variable(tf.truncated_normal([N3, N4], stddev=0.1))\n",
    "B4 = tf.Variable(tf.ones([N4])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y4 = tf.nn.sigmoid(tf.matmul(Y3, W4) + B4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "W5 = tf.Variable(tf.truncated_normal([N4, N5], stddev=0.1)) \n",
    "B5 = tf.Variable(tf.ones([N5])) \n",
    "Ylogits = tf.matmul(Y4, W5) + B5\n",
    "Y = tf.nn.softmax(Ylogits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=Ylogits, labels=Y_)\n",
    "cost_op = tf.reduce_mean(cross_entropy)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization op (backprop)\n",
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(cost_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary to monitor cost tensor\n",
    "tf.summary.scalar(\"cost\", cost_op)\n",
    "# Create a summary to monitor accuracy tensor\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "# Merge all summaries into a single op\n",
    "summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 cost= 73.44\n",
      "Epoch:  0\n",
      "Epoch:  2 cost= 116.14\n",
      "Epoch:  1\n",
      "Epoch:  3 cost= 154.86\n",
      "Epoch:  2\n",
      "Epoch:  4 cost= 189.22\n",
      "Epoch:  3\n",
      "Epoch:  5 cost= 221.13\n",
      "Epoch:  4\n",
      "Epoch:  6 cost= 250.18\n",
      "Epoch:  5\n",
      "Epoch:  7 cost= 279.54\n",
      "Epoch:  6\n",
      "Epoch:  8 cost= 308.09\n",
      "Epoch:  7\n",
      "Epoch:  9 cost= 334.85\n",
      "Epoch:  8\n",
      "Epoch: 10 cost= 360.97\n",
      "Epoch:  9\n",
      "Epoch: 11 cost= 385.55\n",
      "Epoch:  10\n",
      "Epoch: 12 cost= 409.32\n",
      "Epoch:  11\n",
      "Epoch: 13 cost= 432.46\n",
      "Epoch:  12\n",
      "Epoch: 14 cost= 454.98\n",
      "Epoch:  13\n",
      "Epoch: 15 cost= 476.86\n",
      "Epoch:  14\n",
      "Epoch: 16 cost= 498.66\n",
      "Epoch:  15\n",
      "Epoch: 17 cost= 518.75\n",
      "Epoch:  16\n",
      "Epoch: 18 cost= 537.17\n",
      "Epoch:  17\n",
      "Epoch: 19 cost= 556.33\n",
      "Epoch:  18\n",
      "Epoch: 20 cost= 575.09\n",
      "Epoch:  19\n",
      "Optimization Finished!\n",
      "Accuracy:  0.9416\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Run the initializer\n",
    "    sess.run(init_op)\n",
    "    avg_cost = 0.\n",
    "    # op to write logs to TensorBoard\n",
    "    writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "    yM_train = np.zeros(shape=(len(y_train), 10), dtype=float)\n",
    "    for i in range(len(y_train)):\n",
    "        yM_train[i, y_train[i]] = 1\n",
    "    yM_test = np.zeros(shape=(len(y_test), 10), dtype=float)\n",
    "    for i in range(len(y_test)):\n",
    "        yM_test[i, y_test[i]] = 1\n",
    "    for epoch in range(training_epochs):\n",
    "        batch_count = int(len(y_train)/batch_size)\n",
    "        for i in range(batch_count):\n",
    "            start_row = i*batch_size\n",
    "            end_row_plus_one = (i+1)*batch_size\n",
    "            max_learning_rate = 0.003\n",
    "            min_learning_rate = 0.0001\n",
    "            decay_speed = 2000 \n",
    "            batch_x, batch_y = x_train[start_row:end_row_plus_one, :], yM_train[start_row:end_row_plus_one,:]\n",
    "\n",
    "            learning_rate = min_learning_rate+\\\n",
    "                            (max_learning_rate - min_learning_rate)\\\n",
    "                            * math.exp(-i/decay_speed)\n",
    "            _, c,summary = sess.run([train_op, cost_op, summary_op], feed_dict={X: batch_x, Y_: batch_y, lr: learning_rate})\n",
    "            avg_cost += c / batch_count\n",
    "            writer.add_summary(summary, epoch * batch_count + i)\n",
    "        if (epoch+1) % display_epoch == 0:\n",
    "            print(\"Epoch:\", '%2d' % (epoch+1), \"cost=\", \"{:.2f}\".format(avg_cost))   \n",
    "        print(\"Epoch: \", epoch)\n",
    "    print(\"Optimization Finished!\")\n",
    "           \n",
    "    print(\"Accuracy: \", accuracy.eval(feed_dict={X: x_test, Y_: yM_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "index=5\n",
    "print(yM_test[index,:])\n",
    "print(y_test[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
