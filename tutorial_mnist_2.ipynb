{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>There are 2 datasets:</strong><br/>\n",
    "<ol>\n",
    "<li>Training data set,</li>\n",
    "<li>Test data set.</li>\n",
    "</ol>\n",
    "Each of these data sets are .csv files. <br/>\n",
    "Each dataset has 785 columns with a variable number of rows.\n",
    "We shall use the pandas package to read these files. The results are numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_filename=\"C:\\Apps\\Projects\\ml\\data\\mnist\\mnist_train.csv\"\n",
    "tmp=pd.read_csv(training_filename, sep=',', header=None)\n",
    "# train_nrows, train_ncols=tmp.shape\n",
    "x_train, y_train=tmp.loc[:,1:tmp.shape[1]].values, tmp.loc[:,0].values\n",
    "test_filename=\"C:\\Apps\\Projects\\ml\\data\\mnist\\mnist_test.csv\"\n",
    "tmp=pd.read_csv(test_filename, sep=',', header=None)\n",
    "#test_nrows, test_ncols=tmp.shape\n",
    "x_test, y_test=tmp.loc[:,1:tmp.shape[1]].values, tmp.loc[:,0].values\n",
    "tmp=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_path = 'logging/' # logging path\n",
    "batch_size = 100 # batch size while performing training \n",
    "learning_rate = 0.003 # Learning rate \n",
    "training_epochs = 20 # training epoch\n",
    "display_epoch = 1\n",
    "layer_count = np.array([300, 300, 100, 60, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, 784), name='X_Vector')\n",
    "XX = tf.reshape(X, [-1, 784])\n",
    "Y_  = tf.placeholder(tf.float32, shape=(None, 10), name='Y_Vector')\n",
    "lr = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the weights and bias vector\n",
    "W = []\n",
    "B = []\n",
    "Y = []\n",
    "n = len(layer_count)\n",
    "assert layer_count[-1] == 10, \"The final layer must have 10 nodes.\"\n",
    "for i in range(n) :\n",
    "    #print(i)\n",
    "    B.append(tf.Variable(tf.zeros([layer_count[i]])))\n",
    "    if i == 0 :\n",
    "        W.append(tf.Variable(tf.truncated_normal([784, layer_count[i]], stddev=0.1)))\n",
    "        Y.append(tf.nn.sigmoid(tf.matmul(XX, W[i]) + B[i]))\n",
    "    else :\n",
    "        W.append(tf.Variable(tf.truncated_normal([layer_count[i-1], layer_count[i]], stddev=0.1)))\n",
    "        if (i < (n-1)) :\n",
    "            Y.append(tf.nn.sigmoid(tf.matmul(Y[i-1], W[i]) + B[i]))            \n",
    "Ylogits = tf.matmul(Y[n-2], W[n-1]) + B[n-1]\n",
    "Y.append(tf.nn.softmax(Ylogits))\n",
    "    #print(layer_count[i])\n",
    "#W = tf.Variable(tf.truncated_normal([784, N1], stddev=0.1))\n",
    "# Create the bias term\n",
    "#B1 = tf.Variable(tf.zeros([N1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=Ylogits, labels=Y_)\n",
    "cost_op = tf.reduce_mean(cross_entropy)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(Y[-1], 1), tf.argmax(Y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization op (backprop)\n",
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(cost_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary to monitor cost tensor\n",
    "tf.summary.scalar(\"cost\", cost_op)\n",
    "# Create a summary to monitor accuracy tensor\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "# Merge all summaries into a single op\n",
    "summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 cost= 71.22\n",
      "Epoch:  0\n",
      "Epoch:  2 cost= 112.88\n",
      "Epoch:  1\n",
      "Epoch:  3 cost= 148.59\n",
      "Epoch:  2\n",
      "Epoch:  4 cost= 182.63\n",
      "Epoch:  3\n",
      "Epoch:  5 cost= 212.50\n",
      "Epoch:  4\n",
      "Epoch:  6 cost= 240.76\n",
      "Epoch:  5\n",
      "Epoch:  7 cost= 268.16\n",
      "Epoch:  6\n",
      "Epoch:  8 cost= 293.97\n",
      "Epoch:  7\n",
      "Epoch:  9 cost= 319.63\n",
      "Epoch:  8\n",
      "Epoch: 10 cost= 345.50\n",
      "Epoch:  9\n",
      "Epoch: 11 cost= 370.20\n",
      "Epoch:  10\n",
      "Epoch: 12 cost= 393.26\n",
      "Epoch:  11\n",
      "Epoch: 13 cost= 417.03\n",
      "Epoch:  12\n",
      "Epoch: 14 cost= 438.48\n",
      "Epoch:  13\n",
      "Epoch: 15 cost= 460.30\n",
      "Epoch:  14\n",
      "Epoch: 16 cost= 481.24\n",
      "Epoch:  15\n",
      "Epoch: 17 cost= 501.44\n",
      "Epoch:  16\n",
      "Epoch: 18 cost= 521.51\n",
      "Epoch:  17\n",
      "Epoch: 19 cost= 541.98\n",
      "Epoch:  18\n",
      "Epoch: 20 cost= 560.90\n",
      "Epoch:  19\n",
      "Optimization Finished!\n",
      "Accuracy:  0.9306\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Run the initializer\n",
    "    sess.run(init_op)\n",
    "    avg_cost = 0.\n",
    "    # op to write logs to TensorBoard\n",
    "    writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "    yM_train = np.zeros(shape=(len(y_train), 10), dtype=float)\n",
    "    for i in range(len(y_train)):\n",
    "        yM_train[i, y_train[i]] = 1\n",
    "    yM_test = np.zeros(shape=(len(y_test), 10), dtype=float)\n",
    "    for i in range(len(y_test)):\n",
    "        yM_test[i, y_test[i]] = 1\n",
    "    for epoch in range(training_epochs):\n",
    "        batch_count = int(len(y_train)/batch_size)\n",
    "        for i in range(batch_count):\n",
    "            start_row = i*batch_size\n",
    "            end_row_plus_one = (i+1)*batch_size\n",
    "            # Change this\n",
    "            max_learning_rate = 0.003\n",
    "            min_learning_rate = 0.0001\n",
    "            decay_speed = 2000 \n",
    "            batch_x, batch_y = x_train[start_row:end_row_plus_one, :], yM_train[start_row:end_row_plus_one,:]\n",
    "\n",
    "            learning_rate = min_learning_rate+\\\n",
    "                            (max_learning_rate - min_learning_rate)\\\n",
    "                            * math.exp(-i/decay_speed)\n",
    "            _, c,summary = sess.run([train_op, cost_op, summary_op], feed_dict={X: batch_x, Y_: batch_y, lr: learning_rate})\n",
    "            avg_cost += c / batch_count\n",
    "            writer.add_summary(summary, epoch * batch_count + i)\n",
    "        if (epoch+1) % display_epoch == 0:\n",
    "            print(\"Epoch:\", '%2d' % (epoch+1), \"cost=\", \"{:.2f}\".format(avg_cost))   \n",
    "        print(\"Epoch: \", epoch)\n",
    "    print(\"Optimization Finished!\")\n",
    "           \n",
    "    print(\"Accuracy: \", accuracy.eval(feed_dict={X: x_test, Y_: yM_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "index=5\n",
    "print(yM_test[index,:])\n",
    "print(y_test[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
