{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>There are 2 datasets:</strong><br/>\n",
    "<ol>\n",
    "<li>Training data set,</li>\n",
    "<li>Test data set.</li>\n",
    "</ol>\n",
    "Each of these data sets are .csv files. <br/>\n",
    "Each dataset has 785 columns with a variable number of rows.\n",
    "We shall use the pandas package to read these files. The results are numpy arrays.\n",
    "The first column contains the label, the remaining columns contain the pixel data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"C:\\\\Apps\\\\Projects\\\\ml\\\\data\\\\mnist\\\\\"\n",
    "training_filename = root_dir + \"mnist_train.csv\"\n",
    "# Use pandas to read csv file\n",
    "tmp=pd.read_csv(training_filename, sep=',', header=None)\n",
    "# Use df.loc to access a group of rows and columns\n",
    "# Use .values to return the numpy representation.\n",
    "\n",
    "# Read the training data set\n",
    "x_train, y_train=tmp.loc[:,1:tmp.shape[1]].values, tmp.loc[:,0].values\n",
    "\n",
    "# Read the test data set\n",
    "test_filename = root_dir + \"mnist_test.csv\"\n",
    "tmp=pd.read_csv(test_filename, sep=',', header=None)\n",
    "x_test, y_test=tmp.loc[:,1:tmp.shape[1]].values, tmp.loc[:,0].values\n",
    "tmp=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_path = 'logging/' # logging path\n",
    "batch_size = 100 # batch size while performing training \n",
    "learning_rate = 0.003 # Learning rate \n",
    "training_epochs = 30 # training epoch\n",
    "display_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = tf.placeholder(dtype=tf.int32, shape=[], name=\"foo1\")       shape takes a single scalar value directly.\n",
    "# y = tf.placeholder(dtype=tf.int32, shape=[None], name=\"foo2\")   shape takes a 1-dim array\n",
    "# z = tf.placeholder(dtype=tf.int32, shape=None, name=\"foo3\")     shape can take in any value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.placeholder(dtype, shape=None, name=None)\n",
    "#\n",
    "X = tf.placeholder(tf.float32, shape=(None, 784))\n",
    "# Variable number of 28 x 28 x 1 tensors. -1 indicates the dimension is unknown.\n",
    "x_image = tf.reshape(X, [-1, 28, 28, 1])\n",
    "Y_  = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "lr = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A variable maintains state in the graph across calls to run()\n",
    "# Create a variable.\n",
    "# w = tf.Variable(<initial-value>, name=<optional-name>, shape=<optional-shape>)\n",
    "\n",
    "# Truncated normal Outputs random values from a truncated normal distribution.\n",
    "#\n",
    "# tf.random.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.dtypes.float32, seed=None, name=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wt_var(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.constant creates a constant tensor.\n",
    "# tf.constant(value, dtype=None, shape=None, name='Const', verify_shape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_var(shape):\n",
    "    return tf.Variable(tf.constant(0.1, shape=shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes a 2-D convolution given 4-D input and filter tensors.\n",
    "# tf.nn.conv2d(input, filter, strides, padding,\n",
    "#     use_cudnn_on_gpu=True, data_format='NHWC', dilations=[1, 1, 1, 1], name=None)\n",
    "\n",
    "# input = A Tensor\n",
    "# filter = Tensor [filter_height, filter_width, in_channels, out_channels]\n",
    "# strides: A list of ints. 1-D tensor of length 4. \n",
    "#          The stride of the sliding window for each dimension of input\n",
    "#          Usually has the form strides = [1, stride, stride, 1].\n",
    "# padding: A string from: \"SAME\", \"VALID\". The type of padding algorithm to use.\n",
    "\n",
    "# Given an input tensor of shape [batch, in_height, in_width, in_channels]\n",
    "# and a filter / kernel tensor of shape [filter_height, filter_width, in_channels, out_channels]\n",
    "# this op \n",
    "# a) Flattens the filter to a 2-D matrix with shape [filter_height * filter_width * in_channels, output_channels].\n",
    "# b) Extracts image patches from the input tensor to form a virtual tensor of shape \n",
    "#   [batch, out_height, out_width, filter_height * filter_width * in_channels]\n",
    "# c) For each patch, right-multiplies the filter matrix and the image patch vector.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.nn.max_pool(value, ksize, strides, padding, data_format='NHWC', name=None)\n",
    "# \n",
    "# value: A 4-D Tensor of the format specified by data_format.\n",
    "# ksize: A list or tuple of 4 ints. The size of the window for each dimension of the input tensor.\n",
    "# strides: A list or tuple of 4 ints. The stride of the sliding window for each dimension of the input tensor.\n",
    "# padding: A string, either 'VALID' or 'SAME'. The padding algorithm.\n",
    "# data_format: A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported.\n",
    "# name: Optional name for the operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.nn.relu(features, name=None)\n",
    "# \n",
    "# features: A Tensor. \n",
    "# name: A name for the operation (optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv1 = wt_var([3, 3, 1, 32]) # [filter_height, filter_width, in_channels, out_channels] = [28, 28, 1, 32]\n",
    "b_conv1 = bias_var([32])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv2 = wt_var([3, 3, 32, 64]) # [filter_height, filter_width, in_channels, out_channels] = [14, 14, 1, 32]\n",
    "b_conv2 = bias_var([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2) # Output = [7, 7, 1, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected layer\n",
    "W_fc1 = wt_var([7 * 7 * 64, 1024]) # [7 x 7 x 64, 1024]\n",
    "b_fc1 = bias_var([1024])\n",
    "\n",
    "h_pool2_vec = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_vec, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(\"float32\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_fc2 = wt_var([1024, 10])  # Softmax layer\n",
    "b_fc2 = bias_var([10])\n",
    "\n",
    "#y_hat = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "Ylogits = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "y_hat = tf.nn.softmax(Ylogits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_entropy = tf.reduce_sum(Y_ * tf.log(y_hat))\n",
    "#cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=Ylogits, labels=Y_)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=Ylogits, labels=Y_)\n",
    "cost_op = tf.reduce_mean(cross_entropy)*100\n",
    "#cost_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=Ylogits, labels=Y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_hat, 1), tf.argmax(Y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "#cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=Ylogits, labels=Y_)\n",
    "#cost_op = tf.reduce_mean(cross_entropy)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization op (backprop)\n",
    "#train_op = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(cost_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter cell ...\n",
      "Training model ...\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Epoch: 10\n",
      "Epoch: 11\n",
      "Epoch: 12\n",
      "Epoch: 13\n",
      "Epoch: 14\n",
      "Epoch: 15\n",
      "Epoch: 16\n",
      "Epoch: 17\n",
      "Epoch: 18\n",
      "Epoch: 19\n",
      "Epoch: 20\n",
      "Epoch: 21\n",
      "Epoch: 22\n",
      "Epoch: 23\n",
      "Epoch: 24\n",
      "Epoch: 25\n",
      "Epoch: 26\n",
      "Epoch: 27\n",
      "Epoch: 28\n",
      "Epoch: 29\n",
      "Epoch: 30\n",
      "Optimization Finished!\n",
      "Accuracy:  0.9818\n"
     ]
    }
   ],
   "source": [
    "print('Enter cell ...')\n",
    "with tf.Session() as sess:\n",
    "    # Run the initializer\n",
    "    print('Training model ...')\n",
    "    sess.run(init_op)\n",
    "    #avg_cost = 0.\n",
    "    # op to write logs to TensorBoard\n",
    "    writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "    yM_train = np.zeros(shape=(len(y_train), 10), dtype=float)\n",
    "    for i in range(len(y_train)):\n",
    "        yM_train[i, y_train[i]] = 1\n",
    "    yM_test = np.zeros(shape=(len(y_test), 10), dtype=float)\n",
    "    for i in range(len(y_test)):\n",
    "        yM_test[i, y_test[i]] = 1\n",
    "    batch_count = int(len(y_train)/batch_size)\n",
    "    #print(\"Batch count: \", batch_count)\n",
    "    for epoch in range(training_epochs):\n",
    "        for i in range(batch_count):\n",
    "            start_row = i*batch_size\n",
    "            end_row_plus_one = (i+1)*batch_size\n",
    "            # Change this\n",
    "            max_learning_rate = 0.003\n",
    "            min_learning_rate = 0.0001\n",
    "            decay_speed = 2000 \n",
    "            batch_x, batch_y = x_train[start_row:end_row_plus_one, :], yM_train[start_row:end_row_plus_one,:]\n",
    "\n",
    "            learning_rate = min_learning_rate+\\\n",
    "                            (max_learning_rate - min_learning_rate)\\\n",
    "                            * math.exp(-i/decay_speed)\n",
    "            _ = sess.run([train_op], feed_dict={X: batch_x, Y_: batch_y, lr: learning_rate, keep_prob:0.5})\n",
    "            #avg_cost += c / batch_count\n",
    "            #writer.add_summary(epoch * batch_count + i)\n",
    "        if (epoch+1) % display_epoch == 0:\n",
    "            print(\"Epoch:\", '%2d' % (epoch+1)) #, \"cost=\", \"{:.2f}\".format(avg_cost))   \n",
    "        #print(\"Epoch: \", epoch)\n",
    "    print(\"Optimization Finished!\")\n",
    "           \n",
    "    print(\"Accuracy: \", accuracy.eval(feed_dict={X: x_test, Y_: yM_test, keep_prob:1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "index=15\n",
    "print(yM_test[index,:])\n",
    "print(y_test[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
